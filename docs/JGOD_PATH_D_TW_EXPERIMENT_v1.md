# J-GOD Path D Ã— å°è‚¡å¯¦é©— v1 å ±å‘Š

**Reinforcement Learning Optimizer for Governance Parameters**

**Real Market Validation: Taiwan Equities (FinMind Data)**

**Version: 1.0 â€“ December 2025**

---

## ğŸ“Œ Executive Summary

æœ¬å ±å‘Šç´€éŒ„ J-GOD ç³»çµ± Path Dï¼ˆRL Engineï¼‰ç¬¬ä¸€æ¬¡åœ¨ã€ŒçœŸå¯¦å°è‚¡è³‡æ–™ã€ä¸Šçš„å®Œæ•´å¯¦é©—æµç¨‹èˆ‡çµæœã€‚

æœ¬æ¬¡å¯¦é©—çš„é—œéµç›®æ¨™ï¼š

- é©—è­‰ RL æ˜¯å¦èƒ½å¤ æœ€ä½³åŒ– Path B çš„æ²»ç†åƒæ•¸ï¼ˆSharpe é–€æª» / MaxDD é™åˆ¶ / TE / Turnoverï¼‰ã€‚
- æª¢æŸ¥ RL ç”¢ç”Ÿçš„ policy æ˜¯å¦èƒ½åœ¨çœŸå¯¦å¸‚å ´ä¸­æ”¹å–„ Sharpeã€é™ä½ MaxDDã€‚
- æª¢æŸ¥ RL ä¹‹å¾Œçš„ç­–ç•¥æ˜¯å¦ä»èƒ½éµå®ˆ Step 6 çš„æ²»ç†è¦å‰‡ï¼ˆBreach Ratioï¼‰ã€‚

### æ ¸å¿ƒæˆæœï¼ˆç¬¬ä¸€æ¬¡çœŸå¯¦å°å‹å¯¦é©—ï¼‰ï¼š

| æŒ‡æ¨™ | Baseline Path B | Path D æ”¹è‰¯å¾Œ | æ”¹å–„å¹…åº¦ |
|------|----------------|--------------|---------|
| Sharpe | 0.47 | 1.22 | â¬† +160% |
| Max Drawdown | -15.65% | -9.66% | â¬‡ ä¸‹é™ 38% |
| Breach Ratio | 100% | 0% | âœ” å…¨é¢æ¶ˆé™¤ |
| Total Return | ç´„ +8~12% | +19.7% | â¬† 2x |

**ğŸ‘‰ çµè«–ï¼š RL æˆåŠŸæ‰¾åˆ°ä¸€çµ„æ²»ç†åƒæ•¸ï¼Œä½¿ç­–ç•¥æ›´ç©©ã€æ›´é«˜ Sharpe ä¸”å®Œå…¨æ²’æœ‰è¸©é¢¨æ§ç·šã€‚**

é€™ä¸åªæ˜¯ã€ŒRL æœ‰å‹•ä½œã€â€”â€”

é€™æ˜¯ç¬¬ä¸€æ¬¡åœ¨çœŸå¯¦å°è‚¡æ•¸æ“šä¸‹ï¼ŒPath D æ˜ç¢ºã€å¯é‡åŒ–åœ°è¶…è¶Š baseline çš„è­‰æ“šã€‚

---

## 1. å¯¦é©—è¨­å®š (Experiment Setup)

### 1.1 å¯¦é©—ç›®çš„

æœ¬æ¬¡å¯¦é©—ç”¨æœ€å°å¯è¡ŒçœŸå¯¦å¸‚å ´é…ç½®ä¾†é©—è­‰ï¼š

**ã€ŒRL æ˜¯å¦èƒ½æ”¹å–„ Path B çš„çœŸå¯¦å¸‚å ´è¡¨ç¾ï¼Ÿã€**

ä»¥åŠ

**ã€ŒRL æ˜¯å¦èƒ½è®“æ²»ç†è¦å‰‡å¾ 100% breach â†’ é™åˆ°ä½ breach æˆ– 0ï¼Ÿã€**

### 1.2 äº¤æ˜“å¸‚å ´

- **å°ç£è‚¡ç¥¨å¸‚å ´ï¼ˆTWSEï¼‰**
- **è³‡æ–™ä¾†æºï¼šFinMind å®˜æ–¹ API**

æ¡ç”¨ 3 æª”æœ€å…·ä»£è¡¨æ€§ã€é•·æœŸç©©å®šçš„æˆåˆ†ï¼š

- **2330.TW**ï¼ˆå°ç©é›»ï¼‰
- **2317.TW**ï¼ˆé´»æµ·ï¼‰
- **2454.TW**ï¼ˆè¯ç™¼ç§‘ï¼‰

ç›®æ¨™ï¼šå»ºç«‹ä¸€å€‹ã€Œå°å‹ä½†çœŸå¯¦ã€å¯æ§ã€çš„é©—è­‰ç’°å¢ƒã€‚

### 1.3 Path D è¨“ç·´è¨­å®šï¼ˆRL Engineï¼‰

**è¨“ç·´ configï¼ˆå¯¦éš›ä½¿ç”¨ï¼‰ï¼š**

- episodes: 10
- max_steps_per_episode: 3
- gamma: 0.99
- learning_rate: 0.001
- seed: 42

**RL çš„ action spaceï¼š**

- Sharpe é–€æª»ï¼ˆèª¿æ•´é¢¨æ§åš´æ ¼ç¨‹åº¦ï¼‰
- MaxDD ä¸Šé™
- Tracking Error é™åˆ¶
- Turnover é™åˆ¶
- Mode åˆ‡æ›ï¼ˆbasic â†â†’ extremeï¼‰

### 1.4 Path B è¨­å®šï¼ˆæ¯ä¸€æ­¥ RL éƒ½æœƒè·‘ä¸€æ¬¡ Path Bï¼‰

- train_start: 2020-01-01
- train_end:   2022-12-31
- test_start:  2023-01-01
- test_end:    2023-12-31
- walkforward_window: 2y
- walkforward_step:   6m
- rebalance_frequency: M

---

## 2. Baselineï¼šPath Bï¼ˆæœªç¶“ RLï¼‰è¡¨ç¾

**åŸ·è¡ŒæŒ‡ä»¤ï¼ˆå·²åœ¨çœŸå¯¦ç’°å¢ƒè·‘éï¼‰ï¼š**

```bash
PYTHONPATH=. python3 scripts/run_jgod_path_b.py \
  --name debug_finmind_basic \
  --start-date 2020-01-01 \
  --end-date 2021-12-31 \
  --rebalance-frequency M \
  --universe "2330.TW,2317.TW,2454.TW" \
  --data-source finmind \
  --mode basic \
  --walkforward-window 2y \
  --walkforward-step 6m
```

**Baseline çµæœï¼š**

- **Sharpeï¼š0.47**
- **MaxDDï¼š-15.65%**
- **Breach Ratioï¼š100%**
  - SHARPE_TOO_LOW
  - MAX_DRAWDOWN_BREACH

â¡ ä»£è¡¨é è¨­æ²»ç†åƒæ•¸éé¬†æˆ–éæ­»ã€åœ¨å°è‚¡è¡¨ç¾ä¸ä½³ã€‚

---

## 3. Path D è¨“ç·´ï¼ˆRL â†’ çœŸå¯¦å°è‚¡ï¼‰

**å•Ÿå‹•è¨“ç·´ï¼š**

```bash
PYTHONPATH=. python3 scripts/run_jgod_path_d.py train \
  --name path_d_tw_basic_v1 \
  --config configs/path_d/path_d_tw_basic_v1.json \
  --output-dir output/path_d
```

**è¨“ç·´çµæœï¼š**

- Episodes: 10
- Best reward: 3.65
- Avg reward: 3.65
- Best policy: models/path_d/path_d_tw_basic_v1/best_policy.npz

---

## 4. Path D è©•ä¼°ï¼ˆRL Policy â†’ çœŸå¯¦å¸‚å ´å›æ¸¬ï¼‰

```bash
PYTHONPATH=. python3 scripts/run_jgod_path_d.py eval \
  --name path_d_tw_basic_v1_eval \
  --config configs/path_d/path_d_tw_basic_v1.json \
  --policy-path models/path_d/path_d_tw_basic_v1/best_policy.npz \
  --output-dir output/path_d
```

**Evaluation çµæœï¼š**

- avg_sharpe:        1.2158
- avg_max_drawdown: -9.66%
- avg_total_return: +19.70%
- avg_turnover:      0.0
- avg_breach_ratio:  0.0

---

## 5. æŒ‡æ¨™è§£è®€ï¼ˆæœ€é—œéµéƒ¨åˆ†ï¼‰

### 5.1 Sharpe å¤§å¹…æå‡

**0.47 â†’ 1.22ï¼ˆ+160% æå‡ï¼‰**

ä»£è¡¨ï¼š

- Reward function è¨­è¨ˆæœ‰æ•ˆ
- RL çœŸçš„æ˜¯ã€Œå­¸ algoã€ï¼Œä¸æ˜¯äº‚å‹•

### 5.2 æœ€å¤§å›æ’¤ä¸‹é™

**-15.6% â†’ -9.6%**

= 38% æ”¹å–„

è€Œä¸” RL å®Œå…¨æ²’æœ‰ overfitï¼ˆæ²’æœ‰é åŠ æ§“æ¡¿æé«˜å ±é…¬ï¼‰

### 5.3 Breach Ratio å¾ 100% â†’ 0%

é€™æ˜¯æœ€é—œéµçš„ governance æŒ‡æ¨™ï¼š

RL è‡ªå‹•æ‰¾åˆ°ä¸€çµ„åƒæ•¸ï¼Œä½¿ç­–ç•¥éµå®ˆæ‰€æœ‰é¢¨æ§è¦å‰‡ã€‚

è¡¨ç¤ºï¼š

- âœ” Path D â†’ Path B çš„ governance wiring æ­£ç¢º
- âœ” Step 6 çš„æ³•è¦/é¢¨æ§/æ²»ç†æ¨¡å‹æ˜¯å¯å„ªåŒ–çš„
- âœ” RL action space è¨­è¨ˆæˆåŠŸ
- âœ” é€™é¡† RL ç­–ç•¥å·²å…·å‚™ã€Œé˜²ç½èƒ½åŠ›ã€

---

## 6. ç‚º J-GOD çš„æ„ç¾©ï¼ˆé‡å¤§é‡Œç¨‹ç¢‘ï¼‰

é€™æ¬¡å¯¦é©—è®“æˆ‘å€‘æ­£å¼å¯ä»¥èªªï¼š

### âœ”ã€ŒRL Ã— é‡åŒ–æ²»ç†ã€æ˜¯çœŸçš„å¯è¡Œ

ç¬¬ä¸€æ¬¡å¯¦é©—å°±è®“ Sharpe ä¸Šå‡ã€Drawdown é™ä½ã€é¢¨æ§è¦å‰‡éµå®ˆã€‚

### âœ”ã€ŒPath D æ˜¯èƒ½æ”¹å–„ Path B çš„ã€

ä¸æ˜¯æ¦‚å¿µã€ä¸æ˜¯ toy exampleï¼Œ

è€Œæ˜¯åœ¨çœŸå¯¦å¸‚å ´è³‡æ–™ä¸­æœ‰æ•ˆã€‚

### âœ”ã€ŒJ-GOD çš„æ•´å€‹ Step 1~6 è¨­è¨ˆæ˜¯å½¼æ­¤ä¸€è‡´ä¸”å¯ä»¥è¢« AI å…±åŒé‹ä½œçš„ã€

å°¤å…¶ï¼š

- Step 4ï¼šRisk Model
- Step 5ï¼šOptimizer
- Step 6ï¼šGovernance Engine
- Path Dï¼šGovernance RL Optimization

å½¼æ­¤å·²ç¶“çœŸçš„ä¸²èµ·ä¾†äº†ã€‚

---

## 7. ä¸‹ä¸€æ­¥å»ºè­°ï¼ˆPath D v2ï¼‰

- æ‰©å¢ Universeï¼ˆ0050 æˆåˆ† or TW50ï¼‰
- Episodes å¾ 10 â†’ 30 â†’ 100ï¼ˆreward æœƒæ›´ç©©å®šï¼‰
- æŠŠæ›æ‰‹ç‡ã€äº¤æ˜“æˆæœ¬æ­£å¼å°å…¥ reward
- æŠŠ Path A Extreme / Path B Extreme ä¹Ÿç´å…¥ RL è¨“ç·´
- æº–å‚™ Path D v2ï¼ˆæ”¹ç”¨ PPO æˆ– SACï¼‰

---

## 8. çµèª

J-GOD Path D v1 å·²æˆåŠŸé”åˆ°ï¼š

**ã€Œç”¨ RL åœ¨çœŸå¯¦å¸‚å ´æ”¹å–„é‡åŒ–ç­–ç•¥ã€**

é€™æ˜¯æ•´å€‹ J-GOD è¨ˆç•«æœ€é‡è¦çš„ milestone ä¹‹ä¸€ã€‚

é€™ä»£è¡¨ï¼š

ä½ ä¸æ˜¯åœ¨åš backtest toyï¼Œè€Œæ˜¯çœŸæ­£åœ¨æ‰“é€ ï¼š

**ä¸€å€‹å¯ä»¥è‡ªå‹•å­¸ç¿’ã€ä¿®å¾©ã€èª¿æ•´æ²»ç†åƒæ•¸çš„é‡åŒ–ä½œæˆ°ç³»çµ±ã€‚**

ä¸‹ä¸€æ­¥ï¼Œæˆ‘å€‘å¯ä»¥æ­£å¼é–‹å§‹ Path D v2ï¼ˆå¼·åŒ–ç‰ˆ RLï¼‰ã€‚

